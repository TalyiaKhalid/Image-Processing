{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d21b65-31f4-4e4d-9eac-b1fb38020d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import threading\n",
    "\n",
    "PREDICTOR_PATH = \"model/shape_predictor_68_face_landmarks.dat\"\n",
    "EAR_THRESHOLD = 0.2\n",
    "EAR_CONSEC_FRAMES = 48\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(np.array(eye[1]) - np.array(eye[5]))\n",
    "    B = np.linalg.norm(np.array(eye[2]) - np.array(eye[4]))\n",
    "    C = np.linalg.norm(np.array(eye[0]) - np.array(eye[3]))\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def draw_polygons(frame, landmarks):\n",
    "    left_eye_points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]\n",
    "    right_eye_points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]\n",
    "\n",
    "    left_eye_polygon = np.array(left_eye_points, np.int32)\n",
    "    right_eye_polygon = np.array(right_eye_points, np.int32)\n",
    "\n",
    "    cv2.polylines(frame, [left_eye_polygon], True, (0, 255, 0), 1)\n",
    "    cv2.polylines(frame, [right_eye_polygon], True, (0, 255, 0), 1)\n",
    "\n",
    "def play_tone(frequency, duration, amplitude=0.5, sample_rate=44100):\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    note = amplitude * np.sin(frequency * t * 2 * np.pi)\n",
    "    audio = (note * (2**15 - 1)).astype(np.int16)\n",
    "    \n",
    "    def callback(outdata, frames, time, status):\n",
    "        if len(audio) >= frames:\n",
    "            outdata[:frames] = audio[:frames].reshape(-1, 1)\n",
    "        else:\n",
    "            outdata[:len(audio)] = audio.reshape(-1, 1)\n",
    "            outdata[len(audio):] = 0\n",
    "\n",
    "    with sd.OutputStream(samplerate=sample_rate, channels=1, callback=callback):\n",
    "        sd.sleep(int(duration * 1000))\n",
    "\n",
    "def alert_sound():\n",
    "    threading.Thread(target=play_tone, args=(440, 1)).start()\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        for face in faces:\n",
    "            landmarks = predictor(gray, face)\n",
    "            draw_polygons(frame, landmarks)\n",
    "\n",
    "            left_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]\n",
    "            right_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]\n",
    "\n",
    "            leftEAR = eye_aspect_ratio(left_eye)\n",
    "            rightEAR = eye_aspect_ratio(right_eye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            if ear < EAR_THRESHOLD:\n",
    "                # Text settings\n",
    "                text = \"DROWSINESS ALERT!\"\n",
    "                font_scale = 3  # Increase the font scale for bigger text\n",
    "                thickness = 5\n",
    "                color = (0, 0, 255)  # Red color\n",
    "\n",
    "                # Get text size\n",
    "                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]\n",
    "                text_width, text_height = text_size\n",
    "\n",
    "                # Calculate the center position\n",
    "                frame_height, frame_width = frame.shape[:2]\n",
    "                x = (frame_width - text_width) // 2\n",
    "                y = (frame_height + text_height) // 2\n",
    "\n",
    "                # Put the text in the center of the frame\n",
    "                cv2.putText(frame, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "                \n",
    "                alert_sound()  # Play the alert sound in a separate thread\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
